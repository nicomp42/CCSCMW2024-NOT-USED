{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2fba69-f501-49ba-8889-ed49583db0c4",
   "metadata": {},
   "source": [
    "#### HellaSwag\n",
    "#### Research paper: https://arxiv.org/abs/1905.07830\n",
    "#### Copy of data: https://github.com/rowanz/hellaswag\n",
    "\n",
    "## This runs for a few minutes while processing 60K questions in 3 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00214223-41a4-4566-8227-4d2e1df4ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8eee929-0799-4602-b3c6-42aa5b0bef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import contextlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4624b86-8b23-431e-baca-bacbc4a289ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Jupyter Notebook files\n",
    "with contextlib.redirect_stdout(None):\n",
    "    from Json_Processor import *\n",
    "    from Reading_Level import *\n",
    "    from Wordcloud import *\n",
    "    from Word_Processing import *\n",
    "    from Utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcb52f5-c928-4519-bd84-7769dafdc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_question(questions):\n",
    "    '''\n",
    "    Extract a random question \n",
    "    @param list questions: a list of dictionaries, each a question. \n",
    "    @param str source_id: the desired source of the question. Defaults to None for don't care.  \n",
    "    @return: The random question as a dictionary\n",
    "    '''\n",
    "    return random.choice(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0328a99a-27d1-4760-99d7-4eb951c35f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_question(question):\n",
    "    '''\n",
    "    Print a question\n",
    "    @param question dictionary: The question to be printed\n",
    "    @return: None\n",
    "    '''\n",
    "    #print(\"print_question():\", question)\n",
    "    print(\"Input:\", question[\"input\"])\n",
    "    print(\"Target:\", question[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2ed762-5ee5-42e1-8312-526488a4e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_files(path, extension):\n",
    "    '''\n",
    "    Extract data files from a list of file paths\n",
    "    @param path str: The file path to be processed\n",
    "    @param extension string: the file extension to be used when filtering the files in the path. Include the \".\" in this value.\n",
    "    @return list: The list of files with the extension specified\n",
    "    '''\n",
    "    print(\"path:\", path)\n",
    "    all_files = read_directory_contents(path)\n",
    "    return [file for file in all_files if file.endswith(extension)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb974de3-9515-4a2c-ae9c-29e3adbbbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_questions(benchmark_name, question_path):\n",
    "    '''\n",
    "    Read questions from a directory containing one or more quesiton files\n",
    "    @param question_path string: The location of the question file(s)\n",
    "    @return dictionary: key \"questions\" is a list of dictionaries, one dictionary for each question. Key \"data_files\" is a list of the file names that were processed\n",
    "    '''\n",
    "    results = dict()\n",
    "    data_files = get_data_files(benchmark_name + \"/\"  + question_path, \".json\")\n",
    "    #print(data_files)\n",
    "\n",
    "    # ToDo - Pick the correct Processor class for this benchmark\n",
    "    data_processor = HellaSwag_Json_Processor(benchmark_name + \"/\" + question_path, data_files)   \n",
    "    questions = data_processor.read_data()\n",
    "    results[\"questions\"] = questions\n",
    "    results[\"data_files\"] = data_files\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d308140-f455-49a8-a14b-e2b27128b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_from_questions(questions, write_to = None):\n",
    "    '''\n",
    "    Build one long text string from all the questions.\n",
    "    This logic will vary based on the architecture of the benchmark questions.\n",
    "    @param questions list: list of dictionaries, one dictionary per question.\n",
    "    @param write_to string: File path to write the text string. Default is None. \n",
    "    @return String: The text string\n",
    "    '''\n",
    "    text = \"\"\n",
    "    for question in questions:\n",
    "        text += \" \" + str(question[\"input\"]) + \" \" + str(question[\"target\"])\n",
    "    if write_to != None:\n",
    "        write_string_to_file(text, write_to)\n",
    " \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd98d74-56e1-4c59-949d-6bc5ecfe6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_readability_indices(benchmark_name, questions, verbose = True):\n",
    "    '''\n",
    "    Compute readability values using our Reading_Level class\n",
    "    @param questions list: A list of dictionaries, one dictionary per benchmark question\n",
    "    @param verbose bool: True if this function should print the computed values\n",
    "    @return dictionary: key is the readability metric, value is the corresponding score\n",
    "    '''\n",
    "    text = build_text_from_questions(questions)\n",
    "    indices = Reading_Level.compute_readability_indices(benchmark_name, text)\n",
    "\n",
    "    if (verbose):\n",
    "        print(\"Readability Indices:\")\n",
    "        for index, score in indices.items():\n",
    "            print(f\"{index}: {score:.2f}\")\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0fe655-2446-41a2-868c-268e84b0b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(benchmark_name, questions):\n",
    "    '''\n",
    "    Build a word cloud based on the questions in a benchmark\n",
    "    @param questions list: List of dictionaries, each dictionary os a question from the benchmark\n",
    "    @return None\n",
    "    '''\n",
    "    text = build_text_from_questions(questions)\n",
    "\n",
    "    wordcloud = Wordcloud()\n",
    "    wordcloud.generate01(benchmark_name, text, myStopwords={\"Numerical\", \"options\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb8a6c4-19e8-45ef-a4fc-3aafeb33a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_frequency(benchmark_name, questions, verbose = True, min_percentage = 1.0):\n",
    "    '''\n",
    "    Compute the word frequencies in the benchmark questions\n",
    "    @param questions list: List of dictionaries, each dictionary os a question from the benchmark\n",
    "    @param verbose bool: True if the function should print the word frequencies\n",
    "    @param min_percentage float: the smallest percentage that should be printed. Defaults to 1.0\n",
    "    @return set (dictionary, float): ({word:# of times that word appears over all questions}, total words)\n",
    "    '''\n",
    "    text = build_text_from_questions(questions)\n",
    "\n",
    "    word_frequency, count = Word_Processing.compute_word_frequency(text)\n",
    "    sorted_word_frequency = {k: v for k, v in sorted(word_frequency.items(), key=lambda item: item[1], reverse = True)}\n",
    "    count = float(count)\n",
    "    write_dict_to_file(sorted_word_frequency, \".\\\\\" + benchmark_name + \"\\\\results\\\\word_frequency.txt\", length = 100, denominator = count)\n",
    "    if verbose:\n",
    "        print(\"Word Frequency:\")\n",
    "        #for key in [key for key in sorted_word_frequency.keys()][:5]:\n",
    "        for key in sorted_word_frequency.keys():\n",
    "            percentage = (sorted_word_frequency[key] / count)* 100\n",
    "            if percentage >= min_percentage:\n",
    "                print(key, \":\", sorted_word_frequency[key], \",\", '{0:.2f}'.format(percentage))\n",
    "\n",
    "    return (sorted_word_frequency, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeedb2a8-f7cf-46ac-a775-5b7fccae025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_longest_words(benchmark_name, questions, verbose = True):\n",
    "    '''\n",
    "    Compute the longest words appearing across all the questions\n",
    "    @param questions list: List of dictionaries, each dictionary is a question from the benchmark\n",
    "    @param verbose bool: True if the function should print the words\n",
    "    @return set (dictionary, float): ({word:# of times that word appears over all questions}, total words)    \n",
    "    '''\n",
    "\n",
    "    text = build_text_from_questions(questions)\n",
    "\n",
    "    word_length, count = Word_Processing.compute_longest_words(text, min_length = 12)\n",
    "    #sorted_word_lengths = {k: v for k, v in sorted(word_length.items(), key=lambda item: item[1], reverse = True)}\n",
    "    sorted_word_lengths = {k: v for k, v in sorted(word_length.items(), key=lambda item: len(item[0]), reverse = True)}\n",
    "    count = float(count)\n",
    "    if verbose:\n",
    "        print(\"Longest Words:\")\n",
    "        for key in list(sorted_word_lengths.keys())[0:25]:\n",
    "            print(len(key), \", \", key, \":\", sorted_word_lengths[key], \",\", '{0:.2f}'.format((sorted_word_lengths[key] / count)* 100))\n",
    "\n",
    "    # Write all the missing words to a text file\n",
    "    write_dict_keys_to_file(sorted_word_lengths, \".\\\\\" + benchmark_name + \"\\\\results\\\\longest_words.txt\", 100)\n",
    "\n",
    "    return (sorted_word_lengths, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4501ec7e-8061-4ab1-8f13-73900945fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(questions, word):\n",
    "    return Word_Processing.find_word(questions, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a999fd-7ac5-40d8-959c-7c3e81a8246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_words(benchmark_name, questions, verbose = True, very_verbose = False):\n",
    "    \"\"\"\n",
    "    Find words not in the English dictionary. Numbers are ignired in this function.\n",
    "    @param questions dictionary: The data to be processed\n",
    "    @param verbose bool: If true, print some information about the first 10 words not found in the dictionary. Default to True\n",
    "    @param very_verbose bool: If true, print the questions containing the first 10 words that were not found in the dictionary. Default to False.\n",
    "    \n",
    "    @return dictionary: The unique words. key and value are both the unique word\n",
    "    \"\"\"\n",
    "    text = build_text_from_questions(questions, \".\\\\\" + benchmark_name + \"\\\\results\\\\questions_as_text.txt\")\n",
    "    print(\"Text built...\")\n",
    "    english = Word_Processing.load_dictionary()\n",
    "    print(\"Dictionary loaded...\")\n",
    "\n",
    "    words = Word_Processing.split_text(text)\n",
    "    print(\"Text split...\")\n",
    "    words_not_found = dict()\n",
    "    print(\"Processing word list...\")\n",
    "    for word in words:\n",
    "        try:\n",
    "            # If this fails, the word is not a number and we will add it to the dictionary of missing words.\n",
    "            tmp = float(word)\n",
    "        except:\n",
    "            if word.upper() not in english:\n",
    "                words_not_found[word] = word\n",
    "                #words_not_found.add(word)\n",
    "    # Write all the missing words to a text file\n",
    "    write_dict_keys_to_file(words_not_found, \".\\\\\" + benchmark_name + \"\\\\results\\\\words_not_in_dictionary.txt\", length = len(words_not_found))\n",
    "\n",
    "    if verbose:\n",
    "        print(len(words_not_found), \"words not in dictionary\")\n",
    "        print(\"First 10 words not in dictionary:\")\n",
    "        for i, key in enumerate(words_not_found.keys()):\n",
    "            if i >= 10:\n",
    "              break\n",
    "            print(key)\n",
    "    if very_verbose:\n",
    "        print(\"First 10 words not in dictionary and the questions those words appear in:\")\n",
    "        for i, key in enumerate(words_not_found.keys()):\n",
    "            if i >= 10:\n",
    "                break\n",
    "            print(key)\n",
    "            print(key , \"found in\", find_word(questions, key))\n",
    "    \n",
    "    return words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "291ce2a6-090f-4634-b533-e0372a2d4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo():\n",
    "    benchmark_name = \"HellaSwag\"     # ToDo\n",
    "    question_path = \"data/\"\n",
    "    result = load_questions(benchmark_name, question_path)\n",
    "    questions = result[\"questions\"]\n",
    "    data_files = result[\"data_files\"]\n",
    "    print(len(questions), \"questions read from\", len(data_files), \"files in\", question_path)\n",
    "\n",
    "    random_question = get_random_question(questions)\n",
    "\n",
    "    words_not_found = find_missing_words(benchmark_name, questions)\n",
    "\n",
    "    print(\"Random question:\")\n",
    "    print_question(random_question)\n",
    "    \n",
    "    compute_readability_indices(benchmark_name, questions)\n",
    "    \n",
    "    generate_wordcloud(benchmark_name, questions)\n",
    "\n",
    "    compute_word_frequency(benchmark_name, questions)\n",
    "    \n",
    "    compute_longest_words(benchmark_name, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220074d-8dd0-4742-8d18-2462e3f06ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: HellaSwag/data/\n",
      "HellaSwag JsonProcessor.read_json(): reading HellaSwag/data/hellaswag_test.json\n",
      "HellaSwag JsonProcessor.read_json(): reading HellaSwag/data/hellaswag_train.json\n",
      "HellaSwag JsonProcessor.read_json(): reading HellaSwag/data/hellaswag_val.json\n",
      "59950 questions read from 3 files in data/\n",
      "Text built...\n",
      "Dictionary loaded...\n",
      "Text split...\n",
      "Processing word list...\n",
      "12189 words not in dictionary\n",
      "First 10 words not in dictionary:\n",
      "WINDSURFER\n",
      "CARDIO\n",
      "INTERTUBES\n",
      "SLACKLINE\n",
      "SSIA\n",
      "HSOWN\n",
      "KISD\n",
      "DODGEBALL\n",
      "ROLLERBLADING\n",
      "XES\n",
      "Random question:\n",
      "Input: [header] How to melt cheddar cheese [title] Start with mild or sharp cheddar. [step] Cheddar cheese can be labeled mild, sharp, or extra sharp. The level of sharp indicates how long the cheese has been aged.\n",
      "Target:  However, many people find that extra sharp cheddar cheese is ideal because it works best when traveling to a culinary festival or a movie. Don't use strong cheeses, like gouda, and they will quickly break down in the fridge.\n",
      " The amount of aging increases as you go from mild to extra sharp. As the cheese ages, the texture of the cheese changes.\n",
      " [substeps] Consider using only mild or sharp cheddar. If you bought the cheeses in your fridge, they typically have still been softened from cooking.\n",
      " Cheddar cheese (also known as \" white cheese \") usually is aged for several months, so you don't need to cook it for longer than 2 months. And fresh cheddar cheese, when stored refrigerated, usually has a longer shelf life than all other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
